# AI Query System - Custos de Transpar√™ncia Estadual

Um sistema inteligente que converte perguntas em portugu√™s brasileiro para consultas SQL do BigQuery usando **Llama (modelo 100% gratuito)** e executa queries em dados de transpar√™ncia de custos estaduais.

## Funcionalidades

- ü¶ô **Llama AI Gratuito**: Usa modelo Llama local via Ollama (sem custos de API)
- ü§ñ **Convers√£o de Linguagem Natural**: Transforma perguntas em portugu√™s para SQL BigQuery
- üìä **Dados Sint√©ticos**: Gera dados realistas de custos de transpar√™ncia
- üé® **Interface Moderna**: Frontend Vue.js com gr√°ficos e visualiza√ß√µes
-  **Resultados em Tempo Real**: Visualiza√ß√£o imediata com charts e estat√≠sticas

## Estrutura do Projeto

```
windsurf-project/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ llama_agent.py       # Agente Llama gratuito para convers√£o Portugu√™s -> SQL
‚îÇ   ‚îú‚îÄ‚îÄ bigquery_service.py  # Servi√ßo BigQuery
‚îÇ   ‚îú‚îÄ‚îÄ data_generator.py    # Gerador de dados sint√©ticos
‚îÇ   ‚îú‚îÄ‚îÄ app.py              # Aplica√ß√£o Flask original
‚îÇ   ‚îî‚îÄ‚îÄ app_frontend.py     # Aplica√ß√£o Flask com frontend moderno
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ index.html          # Interface Vue.js moderna
‚îÇ   ‚îî‚îÄ‚îÄ package.json        # Depend√™ncias frontend
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ synthetic_transparency_costs.csv  # Dados gerados
‚îú‚îÄ‚îÄ requirements.txt        # Depend√™ncias Python
‚îú‚îÄ‚îÄ .env.example           # Vari√°veis de ambiente
‚îî‚îÄ‚îÄ README.md              # Documenta√ß√£o
```

## Instala√ß√£o (Requer Ollama + Llama)

### Setup Autom√°tico
```bash
cd /Users/user/CascadeProjects/windsurf-project

# Instalar depend√™ncias Python
pip install -r requirements.txt

# Setup autom√°tico do Ollama + Llama
./setup_ollama.sh

# Executar aplica√ß√£o
python src/app_frontend.py
```

### Setup Manual
```bash
# Instalar depend√™ncias Python
pip install -r requirements.txt

# Instalar Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Baixar modelo Llama2 (obrigat√≥rio)
ollama pull llama2

# Iniciar servi√ßo Ollama
ollama serve

# Executar aplica√ß√£o
python src/app_frontend.py
```

## Configura√ß√£o

### Modelo AI (Llama via Ollama) - OBRIGAT√ìRIO
- **Autom√°tico**: Execute `./setup_ollama.sh` para instala√ß√£o completa
- **Manual**: 
  ```bash
  # Instalar Ollama
  curl -fsSL https://ollama.ai/install.sh | sh
  
  # Baixar modelo Llama2 (obrigat√≥rio)
  ollama pull llama2
  
  # Iniciar servi√ßo
  ollama serve
  ```

### Google Cloud BigQuery (Opcional)
- Crie um projeto no Google Cloud Console
- Habilite a API BigQuery
- Configure `GOOGLE_CLOUD_PROJECT` no `.env`
- Para autentica√ß√£o, use gcloud CLI ou arquivo de credenciais

## Uso

### Iniciar a Aplica√ß√£o

```bash
python src/app.py
```

Acesse `http://localhost:5000` no navegador.

### Exemplos de Consultas

- **"Quanto foi gasto com sa√∫de em S√£o Paulo no ano de 2023?"**
- **"Mostrar todos os gastos acima de 10000 reais em educa√ß√£o"**
- **"Qual o total gasto com infraestrutura por estado?"**
- **"Custos do Rio de Janeiro por categoria"**
- **"Contratos de licita√ß√£o em 2023"**

### API Endpoints

#### `POST /api/query`
Converte pergunta em portugu√™s e executa consulta.

**Request**:
```json
{
  "prompt": "Quanto foi gasto com sa√∫de em S√£o Paulo?"
}
```

**Response**:
```json
{
  "success": true,
  "prompt": "Quanto foi gasto com sa√∫de em S√£o Paulo?",
  "generated_sql": "SELECT SUM(amount) as total_gasto FROM transparency_costs WHERE state = 'S√£o Paulo' AND cost_category = 'sa√∫de'",
  "results": [...],
  "row_count": 150,
  "timestamp": "2024-01-06T23:31:00Z"
}
```

#### `GET /api/table-info`
Retorna informa√ß√µes sobre a tabela de dados.

#### `GET /api/health`
Verifica status dos servi√ßos.

#### `POST /api/generate-data`
Gera novos dados sint√©ticos.

## Esquema de Dados

A tabela `transparency_costs` cont√©m:

| Coluna | Tipo | Descri√ß√£o |
|--------|------|-----------|
| id | INTEGER | ID √∫nico |
| state | STRING | Estado brasileiro |
| municipality | STRING | Munic√≠pio |
| cost_category | STRING | Categoria (sa√∫de, educa√ß√£o, etc.) |
| cost_description | STRING | Descri√ß√£o detalhada |
| amount | FLOAT | Valor em reais |
| date | DATE | Data da transa√ß√£o |
| department | STRING | Departamento respons√°vel |
| contract_type | STRING | Tipo de contrato |

## Arquitetura

1. **AI Agent**: Usa Llama2 local (obrigat√≥rio) para converter linguagem natural ‚Üí SQL
2. **Query Service**: Executa SQL no BigQuery ou localmente
3. **Data Generator**: Cria dados sint√©ticos realistas
4. **Web Interface**: Frontend com Flask e TailwindCSS

## Seguran√ßa

- Valida√ß√£o de queries geradas
- Filtros de seguran√ßa para opera√ß√µes SQL
- Tratamento de erros robusto
- Logs de auditoria

## Desenvolvimento

### Testes Locais

```bash
# Testar convers√£o de linguagem
python -c "
from src.ai_agent import AIAgent
agent = AIAgent()
sql = agent.convert_portuguese_to_bigquery('Quanto foi gasto com sa√∫de em S√£o Paulo?')
print(sql)
"
```

### Extens√µes

- Adicionar mais categorias de custos
- Suporte a outros bancos de dados
- An√°lise avan√ßada com gr√°ficos
- Exporta√ß√£o de resultados (CSV, Excel)

## Troubleshooting

### Problemas Comuns

1. **Ollama n√£o conecta**: Verifique se o servi√ßo est√° rodando com `ollama serve` ou `brew services start ollama`
2. **Modelo Llama n√£o encontrado**: Execute `ollama pull llama2` para baixar o modelo
3. **BigQuery n√£o conecta**: Configure credenciais Google Cloud
4. **Dados n√£o aparecem**: Gere dados sint√©ticos via bot√£o "Gerar Dados"
5. **Aplica√ß√£o n√£o inicia**: Certifique-se que o Ollama est√° rodando antes de iniciar a aplica√ß√£o

### Logs

A aplica√ß√£o gera logs detalhados para debugging:

```bash
# Ver logs em tempo real
tail -f /var/log/app.log  # (se configurado)
```

## Licen√ßa

MIT License - use conforme necess√°rio.

## Contribui√ß√µes

Contribui√ß√µes s√£o bem-vindas! Abra issues para bugs ou features.
